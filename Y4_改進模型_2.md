# 🤡 Improvements/改進模型 (下)

> 筆者：109612011 葉騏緯

## 一些 Self-attention 的變型

### Local Attention/Truncated Attention

在[上一篇](/Y4_改進模型_1.md)中提到，self-attention 一大問題在於運算量太大，畢竟我們要計算一個 $N\times N$ 的矩陣。

這邊的想法就是，對一些 task 來說，其實不必真的全部都考慮進去，人類自己知道有一些部份是不需要考慮的。有些問題，或許我們只需看某個位置的左右鄰居，距離更遠的就直接不看， weight 設為 0。

你可能會想說，那這跟 CNN 有什麼差別？是的，這樣一來可能根本沒什麼差別。Truncated Attention 未必能帶給你更好的速度。

### Stride Attention

既然只看左右鄰居不好，那我們跳著格子看呢？這就是 Stride Attention 的想法。

這樣我們不就可以少看一些格子卻一樣看大範圍了嗎？

### Global Attention

上面的兩個方法都是用某個位置來看其他位置發生了什麼。

Global Attention 加了一個 special token，它會去蒐集 sequence 裡每個 token 的資訊。special token 要去 attend 所有人，也會被所有人 attend (還是我們 $q\cdot k$ 的事，不要忘記數學傳送門)，剩下的我們就不管了。所以你本來 $N\times N$ 的矩陣可能現在只剩頭兩個 row 跟頭兩個 column 有值了。

- - -

那我們要怎麼決定用什麼 self-attention 呢？

其實你可以不同 head 用不同的 self-attention，沒人說你一次只能用一個啊！

<img src="https://imgur.com/ccZh5eB.png"  style="display:block;margin:auto;width:40%;height:auto;">

- - -

上述舉的方法還是基於人的想法做出的決策，那我們有沒有可能讓 data 自己來說話呢？

### Clustering

例如，如果數字太小的話，其實直接當 0 影響也不大吧，我們只算可能算出來會很大的部分。

那我們要怎麼決定要算誰才會比較大呢？這邊的想法是，我們可以先做分類，現今有很多快速估算出結果的 clustering 可以使用。我們只拿同一堆的 query 跟 key 我們才做計算，這樣就能提升計算速度。

### Learnable Patterns

如果說 clustering 還受人類對問題的理解影響，那我們其實也可以讓模型來學習這件事啊！當然這就比較複雜了。

- - -

還有很多更猛的想法來改良 self-attention，不過基本的我想就先介紹到這邊就夠了。剩下就交給讀者自己去探索了。

## 在 YOLOv5 加入 self-attention

雖然 YOLOv5 並沒有正式的論文 (其他版是有的，可以參考喔)，但這不妨礙我們大致了解它的架構。

<img src="https://imgur.com/R9lg3b1.png"  style="display:block;margin:auto;width:90%;height:auto;"><br>

<img src="https://user-images.githubusercontent.com/26833433/114286928-349bd600-9a63-11eb-941f-7139ee6cd602.png"  style="display:block;margin:auto;width:90%;height:auto;"><br>

對比一下這張圖，我們現在就更能體會這是在改什麼了：

<img src="https://imgur.com/8B0aHEN.png"  style="display:block;margin:auto;width:90%;height:auto;"><br>

是不是覺得這一塊塊**積木**其實挺眼熟呢？正如我前面說過的，一個模型的架構就是由好幾個積木組起來的。講句老實話，其實我一開始並沒有體會這樣的觀點，反而容易被模型架構的概念圖嚇到，想說怎麼這麼複雜？到處接來接去的。

但要記得，這些模型都是用程式碼寫出來的啊！好的程式寫法本身就能看成一塊塊不同功能組合起來啊！那這些積木內部要怎麼寫？就是用 code 來實現那些**數學傳送門**啊！

對於沒有自己動手刻過一個模型的來說，應該是沒辦法靠自己體會這樣的觀點的。我自己就是這樣，是一直到自己練習去手刻模型了，才恍然大悟，原來根本沒有我想的這麼難。想通這點，那之後想要魔改模型，不就只需要：

1. 搞懂需要加哪些數學傳送門
2. 知道怎麼用打 code 實現數學傳送門
3. 找對位置把積木拚上去

如此一來就改出自己的模型了。

- - -

那些搜尋引擎比較會讓你看到的教學，很多其實都假設你至少有點基礎觀念，例如你可能修過機器學習的課。對我這樣從 0 開始摸索模型的人來說，難免還是太難入門了。

之後的文章我會介紹一些我自己亂查查到的模組。
